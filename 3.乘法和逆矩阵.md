# 乘法和逆矩阵

## 矩阵乘法（四种方法）

eg. $\mathbf{A}\mathbf{B}=\mathbf{C}$，$c_{ij}$为矩阵$\mathbf{C}$中第$i$行，第$j$列元素。以$c_{34}$为例，该元素怎么得到的？该元素是矩阵$\mathbf{A}$第3行与矩阵$\mathbf{B}$第四列点乘得到的：
$$
\begin{align}
c_{34} &= a_{31}b_{14}+a_{32}b_{24}+\dots\\
&=\sum_{k=1}^na_{3,k}b_{k,4}
\end{align}
$$
假设矩阵$\mathbf{A}$是$m\times n$矩阵 （$m$行$n$列），则矩阵$\mathbf{B}$就必须要有$n$行，矩阵$\mathbf{B}$就必须是$n \times p$矩阵。$\mathbf{A}$的总列数必须与$\mathbf{B}$的总行数相等。则矩阵$\mathbf{C}$为$m \times p$矩阵。

以上为矩阵乘法的**一般性原则**（即常规方法）。接下来我们继续以上的假设，试着从***行和列的角度*** 来看矩阵乘法。

eg. $\mathbf{A}\mathbf{B}=\mathbf{C}$，$\mathbf{A}$是$m\times n$矩阵，$\mathbf{B}$是$n \times p$矩阵，矩阵$\mathbf{C}$为$m \times p$矩阵。

将$\mathbf{B}$看做是$p$个列向量并排在一起。用$\mathbf{A}$乘以每个列向量得到$\mathbf{C}$中各列。***$\mathbf{C}$中各列是矩阵$\mathbf{A}$各列的线性组合。***  （即列方法）
$$
\mathbf{A}
\begin{bmatrix}col1 & col2 & \ldots & colp
\end{bmatrix}
=
\begin{bmatrix}\mathbf{A}\cdot col1 & \mathbf{A}\cdot col2 & \ldots & \mathbf{A}\cdot colp
\end{bmatrix}
$$
同理，将$\mathbf{A}$看做$m$个行向量组成。每个行向量乘以$\mathbf{B}$得到$\mathbf{C}$中各行。***$\mathbf{C}$中各行是矩阵$\mathbf{B}$各行的线性组合。***  （即行方法）
$$
\begin{bmatrix}
row1\\
row2\\
\vdots\\
rown
\end{bmatrix}
\mathbf{B}
=
\begin{bmatrix}
row1\cdot\mathbf{B}\\
row2\cdot\mathbf{B}\\
\vdots\\
rown\cdot\mathbf{B}
\end{bmatrix}
$$
最后一种方法为列乘以行，得到的是一个完整的矩阵。

eg. $\begin{bmatrix}2\\3\\4\end{bmatrix}\begin{bmatrix}1&6\end{bmatrix}=\begin{bmatrix}2&12\\3&18\\4&24\end{bmatrix}$

***所以矩阵  $\mathbf{C}$就是矩阵  $\mathbf{A}$各列与矩阵  $\mathbf{B}$各行乘积之和。***
$$
\begin{bmatrix}
col1 & col2 & \ldots & coln
\end{bmatrix}
\begin{bmatrix}
row1 \\ row2 \\ \vdots \\ rown
\end{bmatrix}
=
\begin{bmatrix}col1\end{bmatrix}\begin{bmatrix}row1\end{bmatrix}+
\begin{bmatrix}col2\end{bmatrix}\begin{bmatrix}row2\end{bmatrix}+\ldots\ +
\begin{bmatrix}coln\end{bmatrix}\begin{bmatrix}rown\end{bmatrix}
$$

### 补充知识

事实上，还有其他的方法进行矩阵乘法，比如将矩阵切割成更小的矩阵，对这些小的矩阵块进行乘法。
$$
\begin{bmatrix} 
\mathbf{A_1} & \mathbf{A_2}\\
\mathbf{A_3} & \mathbf{A_4}
\end{bmatrix}
\begin{bmatrix}
\mathbf{B_1} & \mathbf{B_2}\\
\mathbf{B_3} & \mathbf{B_4}
\end{bmatrix}
=
\begin{bmatrix}
\mathbf{A_1}\mathbf{B_1}+\mathbf{A_2}\mathbf{B_3} & \mathbf{A_1}\mathbf{B_2}+\mathbf{A_2}\mathbf{B_4}\\
\mathbf{A_3}\mathbf{B_1}+\mathbf{A_4}\mathbf{B_3} & \mathbf{A_3}\mathbf{B_2}+\mathbf{A_4}\mathbf{B_4}\\
\end{bmatrix}
$$

## 逆（方阵）

方阵$\mathbf{A}$，如果逆矩阵存在，则$\mathbf{A^{-1}}\mathbf{A}=\mathbf{I}$，同时$\mathbf{A}\mathbf{A^{-1}}=\mathbf{I}$，故对于*方阵* ，其左逆矩阵等于右逆矩阵。矩阵$\mathbf{A}$也可称作可逆的或者非奇异的。

奇异矩阵，即不存在逆的矩阵。

eg. $\mathbf{A}=\begin{bmatrix}1 & 3\\ 2 & 6 \end{bmatrix}$不存在逆矩阵。为什么？

如果存在一个非零向量$\mathbf{x}$使得$\mathbf{A}\mathbf{x}=0$，那么矩阵$\mathbf{A}$不可逆。因为假设方阵$\mathbf{A}$可逆，那么$\mathbf{A^{-1}}\mathbf{A}\mathbf{x}=\mathbf{x}$，而$\mathbf{x}$非零，则方阵$\mathbf{A}$不可逆。

eg. $\mathbf{A}=\begin{bmatrix}1 & 3\\2 &7\end{bmatrix}$，$\mathbf{A}$可逆，求$\mathbf{A^{-1}}$。设$\mathbf{A^{-1}}=\begin{bmatrix}a & c\\b & d\end{bmatrix}$。

$\begin{bmatrix}1 & 3\\2 &7\end{bmatrix}\begin{bmatrix}a & c\\b & d\end{bmatrix}=\begin{bmatrix}1 & 0\\0 & 1\end{bmatrix}$

运用之前的方法从列的角度出发，我们可以把要求的逆矩阵拆开成列向量，由此我们就建立了矩阵乘以向量的方程组，即：
$$
\begin{bmatrix}1&3\\2&7\end{bmatrix}
\begin{bmatrix}a\\b\end{bmatrix}=
\begin{bmatrix}1\\0\end{bmatrix}\\
\begin{bmatrix}1&3\\2&7\end{bmatrix}
\begin{bmatrix}c\\d\end{bmatrix}=
\begin{bmatrix}0\\1\end{bmatrix}
$$
我们完全可以按照上一讲的方法，对这两个方程分别进行消元回代求解，但是我们也可以将这两步合二为一通过一次消元操作求得解。由此就引入了高斯-若尔当法。

## 高斯-若尔当法

我们再次运用增广矩阵的概念，将结果矩阵即单位矩阵$\mathbf{I}$添加到矩阵$\mathbf{A}$的右边，即$\begin{bmatrix}1&3&1&0\\2&7&0&1\end{bmatrix}$，然后对这个增广矩阵进行消元操作。
$$
\begin{align}
\begin{bmatrix}1&3&1&0\\2&7&0&1\end{bmatrix} 
&\to \begin{bmatrix}1&3&1&0\\0&1&-2&1\end{bmatrix} \\
&\to \begin{bmatrix}1&0&7&-3\\0&1&-2&1\end{bmatrix}
\end{align}\\
$$
经过消元操作后，右侧的单位矩阵记录了每一步的操作内容，矩阵$\mathbf{A}$变为了单位矩阵$\mathbf{I}$，而右侧的单位矩阵$\mathbf{I}$变换后的结果$\begin{bmatrix}7&-3\\-2&1\end{bmatrix}$就是我们要求的$\mathbf{A}$的逆矩阵$\mathbf{A^{-1}}$。

即，
$$
\begin{bmatrix}\mathbf{A}&\mathbf{I}\end{bmatrix} 
\to \begin{bmatrix}\mathbf{I}&\mathbf{A^{-1}}\end{bmatrix}
$$
我们知道每一步的消元操作都可以用一个矩阵来表示。所有的消元操作可以使用矩阵$\mathbf{E}$来表示，所以
$$
\mathbf{E}\begin{bmatrix}\mathbf{A}&\mathbf{I}\end{bmatrix} 
= \begin{bmatrix}\mathbf{E}\mathbf{A}&\mathbf{E}\end{bmatrix}\\
\mathbf{E}\mathbf{A} = \mathbf{I}\\
$$
这个消元矩阵$\mathbf{E}$就是矩阵$\mathbf{A}$的逆矩阵
$$
\mathbf{E}\begin{bmatrix}\mathbf{A}&\mathbf{I}\end{bmatrix} 
= \begin{bmatrix}\mathbf{I}&\mathbf{A^{-1}}\end{bmatrix}\\
$$
